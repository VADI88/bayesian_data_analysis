{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Poisson - Gamma Example\n",
        "\n",
        "Let's say we're studying the number of customers visiting a coffee shop daily. We observe the number of customers for 10 days and want to infer the average number of daily visits.\n",
        "\n",
        "We can model the daily number of visits as a Poisson distribution, where the rate parameter λ represents the average number of daily visits. Since λ is unknown, we put a Gamma prior on it. The Gamma distribution is a suitable prior for λ because it is always positive and can represent a wide range of shapes depending on its parameters.\n",
        "\n",
        "## Base R\n",
        "\n",
        "-   We think around 10 customers visit the shop per day, but we are not sure of that at all\n",
        "\n",
        "    -   We want the expected value alpha/beta = 10\n",
        "\n",
        "    -   But we want the standard deviation sqrt(alpha) / beta to be high too (maybe around 10?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from cmdstanpy import CmdStanModel, cmdstan_path\n",
        "from scipy.stats import gamma, poisson, nbinom\n",
        "\n",
        "# Prior hyperparameters\n",
        "alpha_prior = 1\n",
        "beta_prior = 0.1\n",
        "\n",
        "# Visualize the prior distribution\n",
        "prior_dist = gamma.rvs(alpha_prior, scale=1/beta_prior, size=1000000)\n",
        "plt.clf()\n",
        "plt.hist(prior_dist, bins=100)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   I think this prior distribution adequately describes my beliefs, because I'm pretty sure that there are fewer than 20 customers per day."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 95% prior credible interval for lambda\n",
        "gamma.ppf(q = [0.025, 0.975], a = alpha_prior, scale = 1/beta_prior)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   We simulate data, but set a seed so it is reproducible.\n",
        "\n",
        "-   This is the 10 days of data we observe from the coffee shop, where we observe between 2 and 9 customers per day."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Simulate some Poisson data\n",
        "np.random.seed(123)  # for reproducibility\n",
        "N = 10\n",
        "true_lambda = 5\n",
        "x = poisson.rvs(true_lambda, size=N)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- We update the parameters and make a histogram of the posterior distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Update parameters\n",
        "alpha_posterior = alpha_prior + np.sum(x)\n",
        "beta_posterior = beta_prior + N\n",
        "\n",
        "# histogram of the posterior distribution\n",
        "plt.clf()\n",
        "plt.hist(gamma.rvs(alpha_posterior, scale=1/beta_posterior, size=100000), bins=100)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Here is a 95% credible interval using qgamma."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 95% posterior credible interval for theta\n",
        "gamma.ppf([0.025, 0.975], a=alpha_posterior, scale = 1/beta_posterior)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-  This is a predictive distribution for future observations, accounting for the inherent daily uncertainty and our uncertainty about the rate $\\lambda$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Predictive distribution\n",
        "lambda_draws = gamma.rvs(alpha_posterior, scale=1/beta_posterior, size=100000)\n",
        "future_obs = poisson.rvs(lambda_draws)\n",
        "plt.clf()\n",
        "plt.hist(future_obs, bins=100)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Here is the predictive distribution directly, which is a negative binomial distribution. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Predictive distribution (Negative binomial)\n",
        "param1 = alpha_posterior\n",
        "param2 = beta_posterior/(beta_posterior + 1)\n",
        "plt.clf()\n",
        "plt.hist(nbinom.rvs(param1, param2, size=100000), bins=100)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stan\n",
        "\n",
        "-   We need to load in the Stan packages and define the Poisson-Gamma model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define Stan model\n",
        "stan_code = '''\n",
        "data {\n",
        "  int<lower=0> N; // number of observations\n",
        "  int<lower=0> y[N]; // observed counts\n",
        "  real<lower=0.1> alpha; // prior hyperparameter\n",
        "  real<lower=0.1> beta; // prior hyperparameter\n",
        "}\n",
        "parameters {\n",
        "  real<lower=0> lambda; // Poisson rate parameter\n",
        "}\n",
        "model {\n",
        "  lambda ~ gamma(alpha, beta); // prior\n",
        "  y ~ poisson(lambda); // likelihood\n",
        "}\n",
        "generated quantities {\n",
        "  int y_pred;\n",
        "  y_pred = poisson_rng(lambda); // posterior predictive distribution\n",
        "}\n",
        "'''\n",
        "\n",
        "# Save model to a file and compile\n",
        "with open(\"model.stan\", \"w\") as file:\n",
        "    file.write(stan_code)\n",
        "model = CmdStanModel(stan_file=\"model.stan\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   We need to simulate the data from above (this is still in my R environment from the example above without Stan, but it doesn't hurt to show it again!)\n",
        "\n",
        "-   Also, we define the hyperparameters and package together all the data for Stan, and fit the model based on the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define data for Stan model\n",
        "data = {\n",
        "    \"N\": N,\n",
        "    \"y\": x,\n",
        "    \"alpha\": alpha_prior,\n",
        "    \"beta\": beta_prior\n",
        "}\n",
        "\n",
        "# Fit the model\n",
        "fit = model.sample(data=data, chains=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   We draw samples to determine our posterior distribution and use it to make a credible interval.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Draw samples to determine our posterior distribution\n",
        "posterior_samples = fit.stan_variable('lambda')\n",
        "\n",
        "# 95% credible interval\n",
        "hpd = np.percentile(posterior_samples, [2.5, 97.5])\n",
        "hpd\n",
        "\n",
        "# Extract the point estimates\n",
        "expected_value = np.mean(posterior_samples)\n",
        "post_median = np.median(posterior_samples)\n",
        "print(f\"Expected value for lambda: {expected_value}\\nPosterior median for lambda: {post_median}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   We can find the point estimates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# MAP estimate (not possible with continuous parameters, we would have to create some analytical \n",
        "# approximation and use that)\n",
        "\n",
        "#map_estimate <- mode(posterior_samples_df$lambda)\n",
        "#cat(\"MAP estimate for lambda: \", map_estimate, \"\\n\")\n",
        "\n",
        "# Posterior mean\n",
        "expected_value = np.mean(posterior_samples)\n",
        "print(\"Expected value for lambda: \", expected_value, \"\\n\")\n",
        "\n",
        "# Posterior median\n",
        "post_median = np.median(posterior_samples)\n",
        "print(\"Posterior median for lambda: \", post_median, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   We can draw posterior samples (which follow a negative binomial distribution)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Posterior predictive samples\n",
        "y_pred_samples = fit.stan_variable('y_pred')\n",
        "plt.clf()\n",
        "plt.hist(y_pred_samples, bins=100)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}